# 빅데이터 & 추천 알고리즘

>  - [1. 데이터 추출 및 정제 과정](#1-데이터-추출-및-정제-과정)
>    - [초기 데이터 수집](#초기-데이터-수집)
>    - [누락 데이터 수집](#누락-데이터-수집)
>    - [이미지 데이터 수집](#이미지-데이터-수집)
>    - [장르 데이터 수집](#장르-데이터-수집)
>    - [추천 게임 계산 코드 전체](#추천-게임-계산-코드-전체)
>  - [2. 추천 알고리즘(KNN) 설명](#2-추천-알고리즘knn-설명)
>    - [협업 필터링 알고리즘(Collaborative Filtering)](#협업-필터링-알고리즘collaborative-filtering)
>    - [KNN 알고리즘 (K-Nearest Neighbor)](#knn-알고리즘-k-nearest-neighbor)
>    - [코사인 유사도(Cosine Similarity)](#코사인-유사도cosine-similarity)
>  - [3. 프로젝트 내 추천 알고리즘 작동 원리](#3-프로젝트-내-추천-알고리즘-작동-원리)
>  - [4. 추천 스케줄링](#4-추천-스케줄링)
>    - [데이터 추천 (Small)](#데이터-추천-small)
>    - [데이터 추천 (Big)](#데이터-추천-big)


## 1. 데이터 추출 및 정제 과정

### 초기 데이터 수집 및 정제

✔ Data Source

스팀 게임 리뷰 (11GB) 2000만 개 이상 리뷰 
- https://www.kaggle.com/datasets/souyama/steam-reviews

스팀 게임 데이터 (500MB) 6만 개 이상 게임
- https://www.kaggle.com/datasets/fronkongames/steam-games-dataset?resource=download

<details>
<summary>데이터 추출 및 정제 코드 (접기/펼치기)</summary>

```python
def condition(data):
    if data["recommendations"] and data["positive"]:
        if "korean" in data["supported_languages"] or "English" in data["supported_languages"]:
            return True
    return False

def get_game_data():
    with open('games/games.json', 'r', encoding='UTF-8') as f:
        raw_data = json.load(f)

    game_data = []
    genre_data = []
    idx = 1

    for id in raw_data:
        temp = raw_data[id]
        if not condition(temp):
            continue
        try:
            dt = temp['release_date']
            dt = datetime.strptime(dt, "%b %d, %Y")
            formatted_date = dt.strftime("%Y-%m-%d")

            is_korean = False
            if "Korean" in temp["supported_languages"]:
                is_korean = True

            score = int(100 * temp['positive'] /
                        (temp['positive'] + temp['negative']))

            fields = {
                'game_name': temp['name'],
                'game_price': temp['price'],
                'released_date': formatted_date,
                'game_description': temp['short_description'],
                'score': score,
                'average_playtime': temp['average_playtime_forever'],
                'publisher': temp['publishers'][0],
                'is_korean': is_korean,
                'windows': temp['windows'],
                'mac': temp['mac'],
                'linux': temp['linux'],
                'peak_ccu': temp['peak_ccu'],
                'average_playtime_2weeks': temp['average_playtime_2weeks'],
                'recommendations': temp['recommendations'],
                'estimated_owners': temp['estimated_owners'],
                'reviews': temp['positive'] + temp['negative'],

            }

            data = {
                'pk': id,
                'model': 'games.game',
                'fields': fields
            }

            game_data.append(data)
            print(idx, end='\r')

        except Exception as e:
            print(id, e)
get_game_data()
```
</details>

✔ 게임 데이터 중에서 `'recommendation'`과 `'positive'`가 있는 게임을 선별하고 그 중에서 `supported_languages`에서 영어와 한글을 지원하는 게임을 선별 (대략 1.2 만개)

✔ 추출된 게임 데이터를 기반으로 리뷰데이터를 정제 (대략 110만개)

### 누락 데이터 수집

✔ 추출한 게임 중에서 리뷰데이터가 없는 게임에 대해 API요청으로 리뷰 데이터 수집 (아래의 코드)

<details>
<summary>데이터 추출 및 정제 코드 (접기/펼치기)</summary>

```python
def get_latest_app_id(i):
    url = f"https://store.steampowered.com/api/appdetails?appids={i}"
    data = requests.get(url).json()
    return data[f"{i}"]["data"]["steam_appid"]
base_url = "https://store.steampowered.com/appreviews/"

# 전체 게임 데이터
total_game_data = []
tc = 1
info = []
no_reviews = []
with open("crawling\\no_reviews.json", 'r', encoding='UTF-8') as f:
    raw_data = json.load(f)
for data in raw_data:
    # 각 게임 데이터
    each_game_data = []
    c = 0
    game_id = get_latest_app_id(data["id"])

    # 게임 아이디로 폴더 없으면 생성
    if not os.path.exists(f"crawling\\{game_id}"):
        os.makedirs(f"crawling\\{game_id}")

    params_id = f"{game_id}/"
    params_cursor = "*"
    max_reviews = 0
    page_count = 0
    while True:

        # API 호출
        try:
            requestData = requests.get(
                f"{base_url}"+f"{params_id}"+"?json=1&num_per_page=100&filter=recent&cursor="+f"{params_cursor}").json()
        except:
            print(
                f"{base_url}"+f"{params_id}"+"?json=1&num_per_page=100&filter=recent&cursor="+f"{params_cursor}")

        nums = requestData["query_summary"]["num_reviews"]

        if params_cursor == "*":
            max_reviews = requestData["query_summary"]["total_reviews"]
        # 다음 커서 만들기
        params_cursor = ""
        next_cursor = requestData["cursor"]
        for char in next_cursor:
            if char == "+":
                params_cursor += "/"
            else:
                params_cursor += char

        for r in requestData["reviews"]:
            # 리뷰 20개 미만 컷
            c += 1
            if r["author"]["num_reviews"] < 20:
                continue

            review_field = {
                "gameid": game_id,
                "steamid": r["author"]["steamid"],
                "playtime": r["author"]["playtime_forever"],
            }
            review_data = {
                "pk": c,
                "models": "reviews.review",
                "fields": review_field
            }
            each_game_data.append(review_data)
            total_game_data.append(review_data)
            print(c, end="\r")

        # 리뷰 없는 게임
        if max_reviews == 0:
            no_reviews.append({
                "id": game_id,
            })

        # 100개 단위인데 내용물이 100개가 안된다면 마지막페이지이므로 종료
        if c >= max_reviews-10:
            break

        if page_count == 10:
            break
        page_count += 1
    info.append([game_id, c])
    print(f"{game_id} : {c}개")
```

</details>

✔ 크롤링한 리뷰 데이터와 기존 추출한 리뷰 데이터를 합쳐서 하나의 json 파일로 만듦

### 이미지 데이터 수집

✔ 게임 이미지의 테이블이 따로 존재하므로 `game_image`에 대한 정보를 따로 추출

<details>
<summary>이미지 데이터 추출 및 정제 코드 (접기/펼치기)</summary>

```python
def get_image_url():
    with open("games.json", "r", encoding="utf8") as file:
        datas = json.load(file)

    game_data = []
    c = 1
    for i, d in enumerate(datas):
        if datas[d]["recommendations"] and datas[d]["positive"]:
            if "Korean" in datas[d]["supported_languages"] or "English" in datas[d]["supported_languages"]:
                fields = {
                    "type": "GAME_HEADER",
                    "type_id": d,
                    "header_image": datas[d]["header_image"],
                }
                data = {
                    "pk": c,
                    "models": "games.image",
                    "fields": fields
                }
                game_data.append(data)
                c += 1
                for sc in datas[d]["screenshots"]:
                    fields = {
                        "type": "GAME_SCREENSHOTS",
                        "type_id": d,
                        "screenshot": sc,
                    }
                    data = {
                        "pk": c,
                        "models": "games.image",
                        "fields": fields
                    }
                    game_data.append(data)
                    c += 1
get_image_url()
```
</details>

### 장르 데이터 수집


✔ 게임 장르의 테이블이 따로 존재하므로 `genre`에 대한 정보를 따로 추출

<details>
<summary>장르 데이터 추출 및 정제 코드 (접기/펼치기)</summary>

```python
genre = []
c = 1
t = len(game_data)
for game in game_data:
    target = game["pk"]
    for g in total_game_data:
        if g == target:
            for game_genre in total_game_data[g]["genres"]:
                for gg in genre:
                    if gg["genre_name"] == game_genre:
                        break
                data = {
                    "game_id": g,
                    "genre_name": game_genre,
                }
                genre.append(data)
                print(c, end="\r", flush=True)
                c += 1
```
</details>

✔ big 데이터의 경우 연산이 오래걸리므로 small 데이터를 따로 추출 (게임 1.2만 개)


### 추천 알고리즘 코드 전체

<details>
<summary>전체 코드 (접기/펼치기)</summary>

```python
def A(df, userid, steamid):
    user_game = GameHistory.objects.filter(user=userid)
    # 순회를 돌면서 모든 게임
    dtypes = {'steam_id': int, 'game_id': int,
              'playtime': int}
    for game in user_game:
        exists_game = GameSmall.objects.filter(game_id=game.game.game_id)
        # 없는 게임에 대한 예외처리
        try:
            if exists_game:
                gameid = game.game.game_id
                playtime = game.total_play_game
                # 가까운 유저 찾기
                game_df = df[df['game_id'] == gameid]
                game_df['playtime_diff'] = abs(game_df['playtime'] - playtime)
                game_df_sorted = game_df.sort_values('playtime_diff')
                closest_rating = game_df_sorted[game_df_sorted['steam_id']
                                                != steamid].iloc[0]['rating']
                # 기존 테이블에 추가
                new_row = {'steam_id': steamid, 'game_id': gameid,
                        'playtime': playtime, 'rating': closest_rating}

                df = df.astype(dtypes).append(new_row, ignore_index=True)
            else:
                print(f"None : {exists_game}")
        except:
            pass
    df = df.astype({'steam_id': int, 'game_id': int,
                    'playtime': int})
    return df

def get_recommend(user, neighbor_list, df):
    user_games = df[df['steam_id'] == user]
    candidates = []
    for neighbor in neighbor_list:
        temp = df[(df['steam_id'] == neighbor) & (
            ~df['game_id'].isin(user_games['game_id']))]
        for index, game in temp.iterrows():
            candidates.append((int(game['game_id']), game['rating']))
    candidates.sort(key=lambda x: x[0])
    flag = ""
    running_sum = 0
    rec_list = []
    count = 0
    for dis in candidates:
        if flag != dis[0]:
            if flag != "":
                rec_list.append((flag, running_sum/count))
            flag = dis[0]
            running_sum = dis[1]
            count = 1
        else:
            running_sum += dis[1]
            count += 1
    sort_list = sorted(rec_list, key=lambda x: x[1], reverse=True)
    return (sort_list)

def get_recommended_games_small(request, user_id):
    # 데이터 불러와서 테이블 만들기
    conn = pymysql.connect(
        host="43.201.61.185",
        user="root",
        password="banapresso77",
        db="gamemakase",
        charset="utf8",
        cursorclass=pymysql.cursors.DictCursor
    )
    cursor = conn.cursor()
    sql = "select * from gamemakase.rating_small"
    cursor.execute(sql)
    result = cursor.fetchall()

    df = pd.DataFrame(result)

    # 가까운 유저 찾아서 테이블에 반영
    user_steamid = user_id
    df = A(df, user_id, user_steamid)

    pivot_table = pd.pivot_table(df, values='rating', index=[
                                 'steam_id'], columns=['game_id'])
    cos_sim_matrix = cosine_similarity(pivot_table.fillna(0))
    cos_sim_df = pd.DataFrame(
        cos_sim_matrix, columns=pivot_table.index, index=pivot_table.index)
    try:
        knn = cos_sim_df[user_steamid].sort_values(ascending=False)[:30]
        knn = list(knn.index)
    except Exception as e:
        print(user_steamid, e)
        return HttpResponse(status=HTTP_201_CREATED)

    json_data_2 = df
    json_data_2.sort_values(by=['steam_id', 'game_id'], ignore_index=True)
    recommend = get_recommend(user_steamid, knn, json_data_2)

    Recommendation.objects.filter(steam_id=user_steamid).delete()
    for game_id, rating in recommend[:100]:
        try:
            game = Game.objects.get(game_id=game_id)
            images = Image.objects.filter(type_id=game_id)
            recommendation = Recommendation(
                steam_id=user_steamid, game_id=game.game_id, rating=rating)
            recommendation.save()
        except Exception as e:
            print(game_id, e)
    # DB 연결 해제
    connection.close()
    return HttpResponse(status=HTTP_201_CREATED)

# 스케줄러 관련
def job():
    print("***********************************************************************************")
    update_recommed()
    print(f"End Time : {time.strftime('%c')}")
    print("***********************************************************************************")

def profile():
    print("***********************************************************************************")
    profile_schedule()
    print(f"End Time : {time.strftime('%c')}")
    print("***********************************************************************************")
    
def schedule_api():
    print("start big data recommend start")
    sched = BackgroundScheduler()
    sched.add_job(job, 'cron', hour='03', minute='0', second='0')
    sched.add_job(profile, 'cron', hour='03', minute='0', second='0')
    try:
        sched.start()
    except Exception as e:
        logging.exception(f"Error in background job: {str(e)}")

schedule_api()
```

</details>



## 2. 추천 알고리즘(KNN) 설명

### 협업 필터링 알고리즘(Collaborative Filtering)

✔ 사용자들의 선호도와 관심사를 분석하여 사용자에게 가장 적합한 아이템을 추천해주는 알고리즘
- 사용자 기반(User-based)
- 아이템 기반(Item-based) 협업

✔ 사용자 기반(User-based) 협업 필터링
-  특정 사용자와 비슷한 취향을 가진 다른 사용자들을 찾고, 그 사용자들이 선호하는 아이템을 추천하는 방식


### KNN 알고리즘 (K-Nearest Neighbor)

✔ 분류 및 회귀 문제를 해결하기 위해 주변 데이터를 기반으로 새로운 데이터 분류하거나 그 값을 예측하는 머신러닝 알고리즘

✔ KNN 알고리즘의 작동 원리
1. 거리 측정 방식 선택 (예: 코사인 유사도, 유클리드 거리, 맨하탄 거리 등)
2. 새로운 데이터 기존 데이터들 사이의 거리를 계산
3. 계산된 거리를 기준으로 가장 가까운 K개의 이웃 데이터를 찾음
4. (회귀 문제의 경우) K개 이웃의 값을 기반으로 (ex 가중 평균) 새로운 데이터의 값을 계산.

### 코사인 유사도(Cosine Similarity)

✔ 두 벡터 간의 코사인 값을 사용하여 벡터 간의 유사도를 측정하는 방법
- 1에 가까울 수록 두 벡터가 유사함을 의미


## 3. 프로젝트 내 추천 알고리즘 작동 원리

1.  rating 테이블로부터 pandas pivot table 생성 [rating은 (해당 유저의 플레이 타임/유저 전체 플레이 타임)]

2. 추천을 할 유저가 플레이한 게임 중에서 DB에 있는 게임을 선별하여 rating을 계산하고 기존 테이블에 추가

3. 찾고자 하는 유저를 기준으로 나머지 코사인 유사도 테이블을 채움

4. rating을 기준으로 내림차순으로 정렬하고 가장 유사한 유저 N명을 선별 (현 서비스에서는 30명)

5. 선별한 N 명의 유저 기반으로 사용자가 플레이 하지 않은 게임에 대한 평점 예측 및 계산

6. 사용자가 플레이하지 않은 게임 중 예상 평점 기준으로 상위 100개를 추천 테이블에 저장


## 4. 추천 스케줄링

✔ 전체 데이터 (게임: 12,000 / 리뷰: 1,100,000)를 기준으로 추천 알고리즘 적용 시 연산에 소모되는 메모리 사용량이 크며 시간이 오래 걸림(전체 유저 기준 10분)

✔ 서비스 이용이 많은 시간에 동작할 경우 서비스 장애가 발생 가능성

✔ 따라서 서비스는 플레이 타임 기반 게임 추천 시 각각 Small / Big(전체) 데이터를 기반으로 한 두 가지 추천 서비스 제공


### 데이터 추천 (Small)

✔ 최초 가입 시에는 따로 추출한 small data(1,200여 개의 게임)으로 추천 알고리즘 적용 

### 데이터 추천 (Big)

✔ 전체 데이터에 대한 추천 알고리즘 계산은 스케줄링을 통해 전체 유저에 대해 서버에서 일괄적으로 진행

✔ `django_apscheduler`를 이용하여 `back ground task`로 매 24시간마다 실행

✔ 서버의 부하를 고려하여 사용자 이용이 적은 03시에 스케줄링

✔ 스팀 유저 프로필 업데이트도 같이 실시
